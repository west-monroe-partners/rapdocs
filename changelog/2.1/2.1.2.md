# 2.1.2

* **AWS Databricks deployment in terraform**
  * Utilize E2 architecture to deploy Databricks E2 workspace in TerraformAdd databricksE2Enabled  = "yes" to terraform variables to enable this feature
* **Azure file output**
* **Agent File Watcher uses archive parameter**
  * Watcher ingestion type needed to use the ingestion parameters for file archiving, similar to scheduled ingestion type
* **Update raw attribute table unique\_flag**
* **Limit number of job retries for job aborted**
  * Occasionally getting legit job aborted error \(bad files, bad data etc\) and the retry logic is putting them in an infinite loop. Added a limit.
* **SQL Server Output**
* **Created Process records for processes that fail before being entered into workflow queue**
  * Previously, processes that failed before an entry for them could be made show up under the previous process on the UI for processes that are a part of a larger chain \(i.e. if the user resets CDC and the Enrichment process fails before it enters the workflow queue, the failure shows up under the CDC process on the UI\)Head processes that failed before they are entered into the workflow queue don't even show up on the UI. \(i.e. if the user resets enrichment and enrichment blows up before a process is entered into the workflow queue, the process does not show up in the UI, and the input is marked as failed immediately\).These processes should still show up on the UI even if they are never entered into the workflow queue.
* **Log all processing messages to stdout**
  * Agent, Core log processing messages to container logsSparky logs processing messages to cluster stdout
* **Update meta.type\_map for SQL Server Output**
  * Made updates to SQL Server Output column data-type mapping to handle the mapping to SQL Server specific data-types
* **Output: Unable to toggle between outputs**

