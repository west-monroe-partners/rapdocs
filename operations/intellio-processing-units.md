# Intellio Processing Units

This section provides an overview of Intellio Processing Units (IPU) and how they are calculated to track usage of the platform for licensing.

## Intellio Processing Units Introduction

In order to best align with the licensing and cost model of the underlying services leverage by Intellio DataOps (e.g. Databricks, AWS/Azure, etc.), the product also adheres to a usage-based cost model which seeks to accurately align value and efficiency gained to price paid for the services.

Cloud providers such as Azure, AWS, Databricks, and Snowflake charge customers based off of the CPU and/or memory of the underlying infrastructure multiplied by the duration those resources are allocated to the customer's use. This aligns well with customer value, as their core services focus on simplifying the management and operations of those infrastructure resources, or the IT Ops around keeping those resources running reliably.

Although Intellio DataOps also provides services to help customers manage their infrastructure resources, the primary value is derived from data engineer development and operations workflow efficiency rather than improving or optimizing the infrastructure the platform runs on.

Because accurately tracking engineering time saved versus an alternative data architecture, methodology, and/or toolsets is not feasible, a surrogate estimation measurement must be used with as many input data elements as possible to ensure clear alignment between product pricing and value.

This measurement of data engineering efficiency for Intellio DataOps is called an Intellio Processing Unit (IPU) and leverages the highly detailed metadata information on user configurations and process tracking to estimate the level of automation and number of processes managed by Intellio DataOps.

## Components of Calculation

The three major components which influence IPU consumption in order of impact are:

1. Number of _successful_ processes executed
2. Weighted calculation of complexity of each successful process
3. Weighted calculation of volume of data processed for each successful process

IPUs are calculated per successful process executed with the following formula:

Process IPUs = (Successful) \* (Weighted Complexity Factor) \* (Weighted Volume Factor)

Consumption is then calculated as SUM(Process IPUs) OVER \<License/Support Term>

### Number of Successful Processes Executed

Each process generated by Intellio and stored in the meta.process\_history has a base weight of 1 IPU. This means that each file processed by IDO will generate at least 4 unweighted base IPUs (Ingestion, Capture Data Changes, Enrichment, and Refresh).

This 1 base IPU per process results in an increase in IPU generation as you change the following settings:

1. Decrease the cadence of schedules or input generation
   * Moving from daily refresh to hourly across all sources will increase IPU generation by an estimated 24x
   * Moving to every 15 minutes from hourly will increase IPU generation by an estimated 4x
2. Adding "Keep Current" rules to source logic
   * Intellio DataOps will generate Attribute Recalculation processes, as well as any downstream processes to ensure the Source data is properly re-processed to update columns to the latest values
   * This can be especially impactful with chained "Keep Current" logic, where an Attribute Recalculation operation changes a field that is then referenced in another Keep Current rule, and so on
   * NOTE: We are actively developing new functionality to reduce the generation of multiple Attribute Recalculation processes against a single source in complex circular Keep Current logic, and will attempt to discount/subtract IPUs from customer's calculated consumption until this feature is released
3. Loopbacks and Multi-pass configuration patterns
   * While sometimes required for complex calculations and transformations impossible with standard ANSI-SQL, engineers should seek to avoid generating new Sources via Loopback patterns or other approaches that require data to be passed through Intellio DataOps multiple times
   * While "Keep Current" patterns also result in increased IPU generation, it is at least 2x less impactful than a loopback pattern due to the extra Ingestion and Change Data Capture processes generated with the loopback pattern
4. Optional Process Enablement, maintenance schedules, etc.
   * Intellio DataOps has a number of optional process types that can be enabled or disabled, such as Data Profiling and Meta Monitor Refresh
   * IDO also has a number of maintenance processes that run on a regular, configurable cadence to help maintain the data lake and reduce cloud spending, such as the Cleanup Process

{% hint style="success" %}
All processes generated by Intellio DataOps are transparently available both in the Processing dashboard within the application, as well as the [Meta Monitoring Dataset](metadata-monitoring-dataset.md)
{% endhint %}

### Weighted Calculation of Complexity

Not all processes are created equally, with some simply passing the data forward to the next processing stage, and others which execute 1000s of lines of generated SQL against billions of rows of data.

Because of the rich metadata IDO stores about each and every code configuration at an extremely granular level, the complexity of each process can be estimated accurately by summarizing and then weighting the configuration applied to each process at time of execution.

The two major sub-components of complexity are:

1. Process Type Base Factor
2. Number of, type, and complexity of rules and/or mappings applied, if applicable

The calculation for Weighted Base Factor for a specific process can be broken down as:

Weighted Base Factor = (Process Type Base Factor) + SUM(Rules/Mappings weight)/100

#### Process Type Base Factor

Some process types require minimal configuration, but have high levels of automation when compared to alternative approaches, others require heavy configuration and provide heavy automation, while a few are extremely lightweight and are separate processes for application architecture purposes.

To account for this, each Process Type has a base factor to either increase or decrease the IPU calculation for each process successfully completed of that Process Type.

These Process Type Base Factors will be published and maintained in the meta.process\_type table starting in version 2.5.1.

#### Rules / Mappings Factors

Each configuration implementing business logic or transformations within IDO will increase the complexity of the codebase generated and managed by the platform. This factor is calculated using metadata about Source Rules and Output Mappings with the following weightings:

Rules:

* Rule with compiled length <= 250 characters = +3 weight
* Rule with compiled length > 250 characters = +8 weight
  * See compiled expression under meta.enrichment -> expression\_parsed
  * Compiled expressions are used to normalize against any non-primary relation traversal syntax differences and source name lengths.
  * Compile expressions ensure users are not punished for using descriptive object names or long-form syntax for their business logic
* Expressions that include an aggregate function over a MANY relation traversal = +5 weight
* Expressions that include a window function = +5 weight

Output Mappings:

* Base Mapping Weight(i.e. \[This].mycolumn) = +1 weight
* Mappings including a traversal through a relation = +3 weight
* Aggregate Function Mappings = +5 weight

Rules are only counted/added to the weight&#x20;
