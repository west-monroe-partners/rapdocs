---
description: Release blog for 5.1.0
---

# 5.1.0 Bug Fixes, Cleanup Configuration, and New Features

### Intellio DataOps 5.1.0 Release <a href="#_toc101170274" id="_toc101170274"></a>

The 5.1.0 minor release is here. Many bugs have been fixed from the 2.5.0 release as well as some additional new features. All the details of the release can be found in the official 5.1.0 release notes. Here are some of the major changes to come with the 5.1.0 version:

### Table of Contents

[Versioning Update](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#versioning-update)

[Workflow Release Hardening and Optimization](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#workflow-release-hardening-and-optimization)

[Improved Performance and Transparency of Database Ingestion](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#improved-performance-and-transparency-of-database-ingestion)

[New Job Runs Tab - Process Page](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#new-job-runs-tab-process-page)

[Output Bugs Squashed - Outputs](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#output-bugs-squashed-outputs)

[Cleanup and Archiving of Data Lake Objects, Logs and Metadata](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#cleanup-and-archiving-of-data-lake-objects-logs-and-metadata)

[S3 Intelligent Tiering Added to Data Lake Bucket in AWS Environments](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#cleanup-and-archiving-of-data-lake-objects-logs-and-metadata)

[Output Name Templates, More Control when Cloning Outputs](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#output-name-templates-more-control-when-cloning-outputs)

[Connection Name Templates, Reduced Manual Cloning Steps](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#connection-name-templates-reduced-manual-cloning-steps)

[The Applied Objects Tab, Environment Configuration Visible](5.1.0-bug-fixes-cleanup-configuration-and-new-features.md#the-applied-objects-tab-environment-configuration-visible)

### Versioning Update

_By: Joe Swanson – Engineering Architect_

Starting with all versions after 2.5.0, Intellio DataOPS versioning will follow the semantic versioning standard. The new versioning will remove the "PlatformVersion" concept and add an interform hotfix number. This will follow the principles of [Semantic Versioning](https://semver.org).

The versioning will be Major.Minor.Hotfix. The first release will use this format; the version will be 5.1.0 instead of 5.1.0. More details on this change can be found[ here](versioning-update-post-2.5.0.md).

### Workflow Release Hardening and Optimization

_By: Vadim Orlov_

The workflow queue release process has been simplified, hardened, and optimized for 5.1.0. All workflow release requests are now persisted in small, Postgres table and are evaluated by core in a queue fashion. This significantly reduces DB load and improves performance. This also improves the reliability of the release process in addition to simplifying the codebase.

### Improved Performance and Transparency of Database Ingestion

_By: Vadim Orlov_

The issue with malformed source query not logging informative error and significantly complicating troubleshooting has been fixed. Part of that fix is an optimization of the database ingestion process by removing initial record count; this is used to determine if batch has any records as well as consolidating it with a single row metadata pull. This will significantly improve ingestion performance.

### New Job Runs Tab - Process Page

_By: Mary Scale – Experienced Consultant_

![Job Runs Tab](../../.gitbook/assets/job\_runs\_2.5.1.png)

Job run details are now available through the Intellio DataOPS user interface. This new feature allows users to sort, filter, and dig into all the job runs in their environment. To navigate to the job runs table, click on Processing from the main menu, then select the Job Runs tab.

Once at the table, users can choose a filter from the Filter Type dropdown. Depending on the filter, users can either select or enter the value of their choosing.

Multiple filters can be selected but only one filter of each type is available. To remove a filter, simply click the “X” on the filter tag. The table will also automatically refresh its data to keep current. Users can load older data by clicking the Load More Data link at the bottom of the table.

Clicking on either the Databricks Run ID or the Databricks Job ID will navigate users to the Intellio Databricks website. The Databricks Run ID shows run details while the Databricks Job ID shows job details. Both links automatically open a new tab.

Cluster settings are also accessible from the table under the Cluster Configuration column. By clicking on the cluster name, users can update or verify the cluster settings for that job run.

Users will also note the multiple date columns present. The Launch column shows the full datetime while all others are formatted for time only. Unless marked with an asterisk, the date value is the same for all date columns within a single row. This reduces the amount of redundant information for the user. To see the full datetime value, hover over the date cell.

Finally, the job run table also displays the stop reasons for terminated jobs. If the stop reason is too large for the table cell, users can see the full value by hovering over the cell. Users can filter and sort on stop reasons. If a job is active, no stop reason should be present.

All documentation on this new feature can be found, [here](https://app.gitbook.com/o/-LhufFV-4p64gkEYvJik/s/-LhufZT729fit8K2vT1H-887967055/\~/changes/zDrOtZtBQnE3CxQGTniZ/user-manual/processing/job-runs).

### Output Bugs Squashed - Outputs

_By: Mary Scale – Experienced Consultant_

Output Settings and Mappings are critical parts of Intellio DataOPS. Thanks to thorough testing, several bugs were uncovered during the development of 5.1.0 and subsequently resolved.

There is now more transparency with auto-mapping messages. Originally, auto-mapping did not always show a save message after use. This was due to users clicking auto-mapping after already having auto-mapped their columns. If a user has already auto-mapped columns, a new message informing the user that the auto-mapping already exists will appear. Should an error occur during saving, a detail error message will display as well.

Another resolved issue occurred involved changed output names. After updating an output’s name in the Settings tab, the new name would not appear in the dropdown navigation until a hard refresh occurred. Now, new names automatically show in the dropdown after saving successfully.

A final bug that was discovered was the inability to select the column datatype on Output Mappings when using auto-map. Today, users can change the column datatype whether they use auto-map or manually enter columns.

### Cleanup and Archiving of Data Lake Objects, Logs and Metadata

_By: Vadim Orlov_

Several new features have been developed:

* Cleanup
  * Old and unused data lake objects&#x20;
  * Files and folders no longer referenced by metadata catalog
    * e.g. deleted sources or inputs
  * &#x20;Old versions of hub table file partitions
* Archiving of database logs to data lake&#x20;
  * Actog, Agent and API logs are now archived into the data lake into /Archive folder as parquet files
* Removal of inputs which have no effective range&#x20;
  * Zero-records and non-current
    * full refresh type

New Cleanup Configuration tab has been added to UI (under System Configuration), which defines cleanup settings. Default cleanup configuration is created automatically and is attached to all existing sources.

### S3 Intelligent Tiering Added to Data Lake Bucket in AWS Environments

_By: Joe Swanson – Engineering Architect_

As part of the cleanup changes, source specific S3 lifecycle rules have been removed and a bucket wide Intelligent Tiering lifecycle rule has been applied to the data lake bucket.

The Intelligent Tiering lifecycle rule applies to objects that are larger than 256kb and have been in the datalike for longer than 24 hours. This storage class optimizes storage costs by automatically moving objects between tiers based on access patterns and is designed to be another vehicle for cost optimization in AWS.

Read more about Intelligent Tiering [here](https://aws.amazon.com/s3/storage-classes/intelligent-tiering/).

### Output Name Templates, More Control when Cloning Outputs

_By: Jacob Crell – Engineering Architect_

Previously, using the clone functionality in Intellio DataOPS often caused an issue with cloning group-specific Outputs.

The previous cloning logic created a new Output Channel in the _same_ Output as the channels that already existed. This logic is outlined in the image below.

![Image 1, original output channel cloning](../../.gitbook/assets/output\_obj1.png)

The desired logic was to have the option of cloning into an entirely new Output. This is shown in the second image.

![Image 2, new output channel cloning](../../.gitbook/assets/output\_obj2.png)

This functionality is enabled in the 5.1.0 release with the addition of Output Name Templates.

Output Name Templates enable users to create an Output name using the Group tokens that are currently used when cloning sources. If the Output uses an Output Name Template, any cloned Source mapped to the Output will create an new Output associated with the new cloned Group.

If the Output does not use an Output Name Template, a cloned Source mapped to the Output will create a new Output Channel mapped into the already existing Output. This is the same logic prior to the 5.1.0 release.

### Connection Name Templates, Reduced Manual Cloning Steps

_By: Jacob Crell – Engineering Architect_

Prior to the 5.1.0 release, newly cloned Sources were created with the exact same connection as the Source they were modeled off. See the image below.

![Image 1, connection templates](../../.gitbook/assets/connection\_temp1.png)

This pattern worked well when cloning multiple Groups that query from the same database. However, if users wanted to use a different Connection for each Group, Source connections had to be manually updated in order to achieve the results below.

![Image 2, connection templates](../../.gitbook/assets/connection\_temp2.png)

Connection Name Templates give the option to automatically implement the new logic, as shown in the second image, when cloning Sources.

A Connection using a Name Template will clone any Source/Output that uses the specified Connection. This will result in a new Connection being created and linked to the new Group.

When a Name Template is not used in a Connection, cloning will result in a new Source/Output mapped to the same Connection as the original Sources/Outputs; this is the same behavior in releases prior to 5.1.0.

### The Applied Objects Tab, Environment Configuration Visible

_By: Jacob Crell – Engineering Architect_

The Applied Objects tab, seen below, is a simple list that shows which Configuration Objects are in use by other IDO Configuration Objects. For example, the Applied Objects tab for a Connection will show the Sources and Outputs that use that Connection. Similarly, the Applied Objects tab for a Schedule will list any Source that uses the Schedule.

The Applied Objects tab appears on the following pages:

·         Connections

·         Schedules

·         Cluster Configuration

·         Process Configuration

·         Source Name Template

·         Output Name Template

·         Connection Name Template

·         Group\
\
